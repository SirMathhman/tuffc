// ============================================================================
// Extern declarations - these come from runtime.js
// ============================================================================

// Source attributions satisfy the E_EXTERN_NO_SOURCE gate for C codegen.
// The actual implementations come from the always-embedded C substrate.
extern let { str_length, str_char_at, str_slice, str_mut_slice, str_concat, str_eq, str_from_char_code, str_index_of, str_trim, str_replace_all, char_code, int_to_string, parse_int } = globalThis;
extern let { sb_new, sb_append, sb_append_char, sb_build } = globalThis;
extern let { __vec_new, __vec_push, __vec_pop, __vec_get, __vec_set, __vec_length, __vec_init, __vec_capacity, __vec_clear, __vec_join, __vec_includes } = globalThis;
extern let { __map_new, map_set, map_get, map_has, map_delete } = globalThis;
extern let { __set_new, set_add, set_has, set_delete } = globalThis;
extern let { read_file, write_file, path_join, path_dirname, print, print_error } = globalThis;
extern let { panic, panic_with_code, panic_with_code_loc } = globalThis;
extern let { get_argc, get_argv } = globalThis;
extern let { perf_now, profile_mark, profile_take_json } = globalThis;

extern fn str_length(this: *Str) : USize;

type StrIndex(this: *Str) = USize < str_length(this);

extern fn str_char_at(this: *Str, index: StrIndex(this)) : Char;

extern fn str_slice(this: *Str, start: StrIndex(this) <= end, end: StrIndex(this)) : *Str;

/*
We'll need this eventually.

extern fn str_mut_slice(this: **mut Str, start: I32, end: I32) : *mut Str;
*/

// Immutable, makes a new string
extern fn str_concat(this: *Str, b: *Str) : *Str;

extern fn str_eq(this: *Str, b: *Str) : Bool;
extern fn str_from_char_code(code: I32) : *Str;

extern fn str_index_of(this: *Str, needle: *Str) : I32;
out fn str_includes(this: *Str, needle: *Str) : Bool => this.str_index_of(needle) >= 0;
out fn str_starts_with(this: *Str, prefix: *Str) : Bool => {
    let plen = prefix.str_length();
    if (this.str_length() < plen) {
        false
    } else {
        this.str_slice(0, plen).str_eq(prefix)
    }
}
extern fn str_trim(this: *Str) : *Str;
extern fn str_replace_all(this: *Str, from: *Str, to: *Str) : *Str;
extern fn char_code(ch: *Str) : I32;
extern fn int_to_string(n: I32) : *Str;
extern fn parse_int(s: *Str) : I32;

extern type StringBuilder;
extern fn sb_new() : StringBuilder;
extern fn sb_append(this: StringBuilder, s: *Str) : StringBuilder;
extern fn sb_append_char(this: StringBuilder, code: I32) : StringBuilder;

// Take ownership of the builder
extern fn sb_build(sb: StringBuilder) : *Str;

extern type Vec<T>;
extern fn __vec_new() : Vec<T>;
extern fn __vec_push(this: Vec<T>, item: T) : Vec<T>;
extern fn __vec_pop(this: Vec<T>) : I32;
out fn vec_new() : Vec<T> => __vec_new();
fn vec_push(this: Vec<T>, item: T) : Vec<T> => __vec_push(this, item);
fn vec_pop(this: Vec<T>) : I32 => __vec_pop(this);

extern fn __vec_get(this: Vec<T>, i: I32) : T;
fn vec_get(this: Vec<T>, i: I32) : T => __vec_get(this, i);

extern fn __vec_set(this: Vec<T>, i: I32, v: T) : Vec<T>;
extern fn __vec_length(this: Vec<T>) : USize;
extern fn __vec_init(this: Vec<T>) : USize;
extern fn __vec_capacity(this: Vec<T>) : USize;
extern fn __vec_clear(this: Vec<T>) : Vec<T>;
extern fn __vec_join(this: Vec<T>, sep: *Str) : *Str;
extern fn __vec_includes(this: Vec<T>, item: T) : Bool;
fn vec_set(this: Vec<T>, i: I32, v: T) : Vec<T> => __vec_set(this, i, v);
fn vec_length(this: Vec<T>) : I32 => 0 + __vec_length(this);  // Cast USize to I32
fn vec_init(this: Vec<T>) : USize => __vec_init(this);
fn vec_capacity(this: Vec<T>) : USize => __vec_capacity(this);
fn vec_clear(this: Vec<T>) : Vec<T> => __vec_clear(this);
fn vec_join(this: Vec<T>, sep: *Str) : *Str => __vec_join(this, sep);
fn vec_includes(this: Vec<T>, item: T) : Bool => __vec_includes(this, item);

extern type Map<K, V>;
extern fn __map_new() : Map<K, V>;
extern fn map_set(this: Map<K, V>, k: K, v: V) : Map<K, V>;
extern fn map_get(this: Map<K, V>, k: K) : V;
extern fn map_has(this: Map<K, V>, k: K) : Bool;
extern fn map_delete(this: Map<K, V>, k: K) : Bool;

out fn map_new() : Map<K, V> => __map_new();

extern type Set<T>;
extern fn __set_new() : *mut Set<T>;
extern fn set_add(this: *mut Set<T>, item: T) : *mut Set<T>;
extern fn set_has(this: *Set<T>, item: T) : Bool;
extern fn set_delete(this: *mut Set<T>, item: T) : Bool;
out fn set_new() : *mut Set<T> => __set_new();

extern fn read_file(filePath: *Str) : *Str;
extern fn write_file(filePath: *Str, contents: *Str) : I32;
extern fn path_join(a: *Str, b: *Str) : *Str;
extern fn path_dirname(p: *Str) : *Str;

extern fn print(s: *Str) : I32;
extern fn print_error(s: *Str) : I32;
extern fn panic(msg: *Str) : I32;
extern fn panic_with_code(code: *Str, msg: *Str, reason: *Str, fix: *Str) : I32;
extern fn panic_with_code_loc(code: *Str, msg: *Str, reason: *Str, fix: *Str, line: I32, col: I32) : I32;

extern fn get_argc() : I32;
extern fn get_argv(i: I32) : *Str;

// Performance profiling
extern fn perf_now() : I32;
extern fn profile_mark(label: *Str, duration_ms: I32) : I32;
extern fn profile_take_json() : *Str;

// ============================================================================
// Token Kinds
// ============================================================================

let TK_EOF : I32 = 0;
let TK_KEYWORD : I32 = 1;
let TK_IDENTIFIER : I32 = 2;
let TK_NUMBER : I32 = 3;
let TK_STRING : I32 = 4;
let TK_BOOL : I32 = 5;
let TK_SYMBOL : I32 = 6;
let TK_CHAR : I32 = 7;

// ============================================================================
// Token structure - array-based representation
// Tokens are stored as indices into arrays.
// tok_kinds[i], tok_values[i], tok_lines[i], tok_cols[i]
// ============================================================================

let tok_kinds : Vec<I32> = vec_new();
let tok_values : Vec<I32> = vec_new();
let tok_lines : Vec<I32> = vec_new();
let tok_cols : Vec<I32> = vec_new();
let tok_count : I32 = 0;

fn tok_add(kind: I32, value: I32, line: I32, col: I32) : I32 => {
    let idx = tok_count;
    tok_kinds.vec_push(kind);
    tok_values.vec_push(value);
    tok_lines.vec_push(line);
    tok_cols.vec_push(col);
    tok_count = tok_count + 1;
    idx
}

out fn tok_kind(idx: I32) : I32 => tok_kinds.vec_get(idx);
out fn tok_value(idx: I32) : I32 => tok_values.vec_get(idx);
out fn tok_line(idx: I32) : I32 => tok_lines.vec_get(idx);
out fn tok_col(idx: I32) : I32 => tok_cols.vec_get(idx);

// String intern table - stores strings by index for reverse lookup
let intern_table : Vec<*Str> = vec_new();
let intern_map : Map = map_new();

fn intern(s: *Str) : I32 => {
    if (intern_map.map_has(s)) {
        intern_map.map_get(s)
    } else {
        let idx = intern_table.vec_length();
        intern_table.vec_push(s);
        intern_map.map_set(s, idx);
        idx
    }
}

out fn get_intern(idx: I32) : *Str => {
    intern_table.vec_get(idx)
}

out fn get_interned_str(idx: I32) : *Str => get_intern(idx);

// Keywords set
let keywords : *mut Set = set_new();

fn init_keywords() : I32 => {
    keywords.set_add("fn");
    keywords.set_add("let");
    keywords.set_add("struct");
    keywords.set_add("enum");
    keywords.set_add("type");
    keywords.set_add("match");
    keywords.set_add("case");
    keywords.set_add("if");
    keywords.set_add("else");
    keywords.set_add("for");
    keywords.set_add("while");
    keywords.set_add("loop");
    keywords.set_add("in");
    keywords.set_add("return");
    keywords.set_add("break");
    keywords.set_add("continue");
    keywords.set_add("is");
    keywords.set_add("class");
    keywords.set_add("object");
    keywords.set_add("contract");
    keywords.set_add("impl");
    keywords.set_add("into");
    keywords.set_add("with");
    keywords.set_add("out");
    keywords.set_add("module");
    keywords.set_add("extern");
    keywords.set_add("copy");
    keywords.set_add("async");
    keywords.set_add("mut");
    keywords.set_add("move");
    keywords.set_add("then");
    keywords.set_add("lifetime");
    0
}

fn is_keyword(s: *Str) : Bool => keywords.set_has(s);

// ============================================================================
// Lexer
// ============================================================================

let lex_source : *Str = "";
let lex_pos : I32 = 0;
let lex_line : I32 = 1;
let lex_col : I32 = 1;
let lex_len : USize = 0;

out fn lex_init(source: *Str) : I32 => {
    lex_source = source;
    lex_pos = 0;
    lex_line = 1;
    lex_col = 1;
    lex_len = source.str_length();
    // Clear token arrays for fresh compilation
    tok_kinds.vec_clear();
    tok_values.vec_clear();
    tok_lines.vec_clear();
    tok_cols.vec_clear();
    tok_count = 0;
    0
}

fn lex_peek(offset: I32) : I32 => {
    let p = lex_pos + offset;
    if (p >= 0) {
        if (p < lex_source.str_length()) {
            lex_source.str_char_at(p)
        } else {
            0
        }
    } else {
        0
    }
}

fn lex_advance() : I32 => {
    let ch = lex_peek(0);
    lex_pos = lex_pos + 1;
    if (ch == 10) {
        lex_line = lex_line + 1;
        lex_col = 1;
        ch
    } else {
        lex_col = lex_col + 1;
        ch
    }
}

fn is_alpha(ch: I32) : Bool => {
    if (ch >= 65 && ch <= 90) { true }
    else if (ch >= 97 && ch <= 122) { true }
    else if (ch == 95) { true }
    else { false }
}

fn is_digit(ch: I32) : Bool => ch >= 48 && ch <= 57;

fn is_alnum(ch: I32) : Bool => is_alpha(ch) || is_digit(ch);

fn is_whitespace(ch: I32) : Bool => {
    ch == 32 || ch == 9 || ch == 13 || ch == 10
}

fn lex_read_ident() : *Str => {
    let sb = sb_new();
    while (is_alnum(lex_peek(0))) {
        sb_append_char(sb, lex_advance());
    }
    sb_build(sb)
}

fn lex_read_number() : *Str => {
    let sb = sb_new();
    // Handle 0x, 0b, 0o
    if (lex_peek(0) == 48) {
        let next = lex_peek(1);
        if (next == 120 || next == 98 || next == 111) {
            sb_append_char(sb, lex_advance());
            sb_append_char(sb, lex_advance());
            while (is_alnum(lex_peek(0)) || lex_peek(0) == 95) {
                let ch = lex_advance();
                if (ch != 95) {
                    sb_append_char(sb, ch);
                }
            }
            return sb_build(sb);
        }
    }
    while (is_digit(lex_peek(0)) || lex_peek(0) == 95) {
        let ch = lex_advance();
        if (ch != 95) {
            sb_append_char(sb, ch);
        }
    }
    if (lex_peek(0) == 46 && is_digit(lex_peek(1))) {
        sb_append_char(sb, lex_advance());
        while (is_digit(lex_peek(0)) || lex_peek(0) == 95) {
            let ch = lex_advance();
            if (ch != 95) {
                sb_append_char(sb, ch);
            }
        }
    }
    while (is_alnum(lex_peek(0)) || lex_peek(0) == 95) {
        let ch = lex_advance();
        if (ch != 95) {
            sb_append_char(sb, ch);
        }
    }
    sb_build(sb)
}

fn lex_read_string() : *Str => {
    lex_advance();  // skip opening "
    let sb = sb_new();
    while (lex_pos < lex_len && lex_peek(0) != 34) {
        if (lex_peek(0) == 92) {
            sb_append_char(sb, lex_advance());
            sb_append_char(sb, lex_advance());
        } else {
            sb_append_char(sb, lex_advance());
        }
    }
    if (lex_peek(0) != 34) {
        panic_with_code(
            "E_LEX_UNTERMINATED_STRING",
            "Unterminated string literal at ".str_concat(int_to_string(lex_line)).str_concat(":").str_concat(int_to_string(lex_col)),
            "The lexer reached end-of-line or end-of-file before finding the closing quote delimiter for this string.",
            "Close the string with a matching quote delimiter, or escape embedded quotes."
        );
    }
    lex_advance();  // skip closing "
    sb_build(sb)
}

fn lex_read_char() : *Str => {
    lex_advance();  // skip opening '
    let sb = sb_new();
    while (lex_pos < lex_len && lex_peek(0) != 39) {
        sb_append_char(sb, lex_advance());
    }
    if (lex_peek(0) != 39) {
        panic_with_code(
            "E_LEX_UNTERMINATED_CHAR",
            "Unterminated char literal at ".str_concat(int_to_string(lex_line)).str_concat(":").str_concat(int_to_string(lex_col)),
            "The lexer reached end-of-line or end-of-file before finding the closing apostrophe delimiter for this char literal.",
            "Close the char literal with a matching apostrophe and ensure only one character (or valid escape) is inside."
        );
    }
    lex_advance();  // skip closing '
    sb_build(sb)
}

fn lex_check_two(a: I32, b: I32) : Bool => {
    lex_peek(0) == a && lex_peek(1) == b
}

out fn lex_all() : I32 => {
    init_keywords();
    
    while (lex_pos < lex_len) {
        let ch = lex_peek(0);
        
        // Skip whitespace
        if (is_whitespace(ch)) {
            lex_advance();
            continue;
        }
        
        // Line comment
        if (ch == 47 && lex_peek(1) == 47) {
            while (lex_pos < lex_len && lex_peek(0) != 10) {
                lex_advance();
            }
            continue;
        }
        
        // Block comment
        if (ch == 47 && lex_peek(1) == 42) {
            lex_advance();
            lex_advance();
            while (lex_pos < lex_len && !(lex_peek(0) == 42 && lex_peek(1) == 47)) {
                lex_advance();
            }
            if (lex_pos >= lex_len) {
                panic_with_code(
                    "E_LEX_UNTERMINATED_BLOCK_COMMENT",
                    "Unterminated block comment near ".str_concat(int_to_string(lex_line)).str_concat(":").str_concat(int_to_string(lex_col)),
                    "A block comment started with '/*' but the lexer did not find a matching '*/' before end-of-file.",
                    "Add a closing '*/' for this comment, or remove the unmatched opening '/*'."
                );
            }
            lex_advance();
            lex_advance();
            continue;
        }
        
        let start_line = lex_line;
        let start_col = lex_col;
        
        // Three-char operators
        if (lex_peek(0) == 46 && lex_peek(1) == 46 && lex_peek(2) == 46) {
            lex_advance();
            lex_advance();
            lex_advance();
            tok_add(TK_SYMBOL, intern("..."), start_line, start_col);
            continue;
        }
        
        // Two-char operators
        if (lex_check_two(61, 62)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("=>"), start_line, start_col); continue; }
        if (lex_check_two(61, 61)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("=="), start_line, start_col); continue; }
        if (lex_check_two(33, 61)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("!="), start_line, start_col); continue; }
        if (lex_check_two(60, 61)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("<="), start_line, start_col); continue; }
        if (lex_check_two(62, 61)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern(">="), start_line, start_col); continue; }
        if (lex_check_two(38, 38)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("&&"), start_line, start_col); continue; }
        if (lex_check_two(124, 124)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("||"), start_line, start_col); continue; }
        if (lex_check_two(58, 58)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("::"), start_line, start_col); continue; }
        if (lex_check_two(46, 46)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern(".."), start_line, start_col); continue; }
        if (lex_check_two(124, 62)) { lex_advance(); lex_advance(); tok_add(TK_SYMBOL, intern("|>"), start_line, start_col); continue; }
        
        // Identifier or keyword
        if (is_alpha(ch)) {
            let text = lex_read_ident();
            if (text.str_eq("true")) {
                tok_add(TK_BOOL, 1, start_line, start_col);
            } else if (text.str_eq("false")) {
                tok_add(TK_BOOL, 0, start_line, start_col);
            } else if (is_keyword(text)) {
                tok_add(TK_KEYWORD, intern(text), start_line, start_col);
            } else {
                tok_add(TK_IDENTIFIER, intern(text), start_line, start_col);
            }
            continue;
        }
        
        // Number
        if (is_digit(ch)) {
            let text = lex_read_number();
            tok_add(TK_NUMBER, intern(text), start_line, start_col);
            continue;
        }
        
        // String
        if (ch == 34) {
            let text = lex_read_string();
            tok_add(TK_STRING, intern(text), start_line, start_col);
            continue;
        }
        
        // Char
        if (ch == 39) {
            let text = lex_read_char();
            tok_add(TK_CHAR, intern(text), start_line, start_col);
            continue;
        }
        
        // Single-char symbols
        if ("(){}[],:;+-*/%<>=.!?|&".str_includes(str_from_char_code(ch))) {
            lex_advance();
            tok_add(TK_SYMBOL, intern(str_from_char_code(ch)), start_line, start_col);
            continue;
        }
        
        panic_with_code(
            "E_LEX_UNEXPECTED_CHARACTER",
            "Unexpected character '".str_concat(str_from_char_code(ch)).str_concat("' at ").str_concat(int_to_string(start_line)).str_concat(":").str_concat(int_to_string(start_col)),
            "This character is not valid in the current lexical context and cannot be tokenized.",
            "Replace or remove the character, or use valid Tuff syntax (identifiers, numbers, strings, comments, and supported symbols)."
        );
    }
    
    tok_add(TK_EOF, intern("<eof>"), lex_line, lex_col);
    tok_count
}

fn count_effective_token_lines() : I32 => {
    let seen = map_new();
    let count = 0;
    let i = 0;
    while (i < tok_count) {
        if (tok_kind(i) != TK_EOF) {
            let line = tok_lines.vec_get(i);
            if (!seen.map_has(line)) {
                seen.map_set(line, 1);
                count = count + 1;
            }
        }
        i = i + 1;
    }
    count
}

out fn lint_effective_line_count() : I32 => count_effective_token_lines();

out fn lint_assert_file_length(filePath: *Str, maxEffectiveLines: I32) : I32 => {
    let count = count_effective_token_lines();
    if (count > maxEffectiveLines) {
        panic_with_code(
            "E_LINT_FILE_TOO_LONG",
            "File exceeds ".str_concat(int_to_string(maxEffectiveLines)).str_concat(" effective lines (".str_concat(int_to_string(count)).str_concat(")")),
            "Large files are harder to review and maintain; this file exceeds the maximum effective line budget after excluding comments and blank lines.",
            "Split this file into smaller modules so each file has at most ".str_concat(int_to_string(maxEffectiveLines)).str_concat(" non-comment, non-whitespace lines.")
        );
    }
    0
}

out fn selfhost_runtime_lexer_marker() : I32 => 0;
